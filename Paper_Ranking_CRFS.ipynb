{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import six\n",
    "import sys\n",
    "#print (sys.executable)\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "#!{sys.executable} -m pip install xgboost\n",
    "#!{sys.executable} -m pip install imblearn\n",
    "#!{sys.executable} -m pip install shap\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "#!pip3 install imblearn\n",
    "#!pip3 install xgboost\n",
    "#!pip3 install shap\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "\n",
    "from filter_CRFS import Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "\n",
    "def clean_plot(leg=True, grid=None, font=None):\n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    \n",
    "    axis_color = 'lightgrey'\n",
    "    ax.spines['bottom'].set_color(axis_color)\n",
    "    ax.spines['left'].set_color(axis_color)\n",
    "    ax.tick_params(axis='both', color=axis_color)\n",
    "    \n",
    "    if leg:\n",
    "        ax.legend(frameon = False, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "        \n",
    "    if grid is not None:\n",
    "        plt.grid(color='lightgrey', axis = grid, linestyle='-', linewidth=.5)\n",
    "        \n",
    "    if font is not None:\n",
    "        for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "            ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            \n",
    "            item.set_fontfamily(font['family'])\n",
    "            item.set_color(font['color'])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*REQUIRED FOR MACINE LEARNING MODEL - Generating Classifier from Apple/Cheese/Chicken/Corn_oil/Ginger/Mussel/Peanut/Potato/Soybean/Tomato/Wheat Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrain = pd.read_excel(\"Apple_scoring.xlsx\", engine='openpyxl')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "atrain['food'] = 'apple'\n",
    "chetrain = pd.read_excel(\"Cheese_scoring.xlsx\", engine='openpyxl')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "chetrain['food'] = 'cheese'\n",
    "chitrain = pd.read_excel(\"Chicken_scoring.xlsx\", engine='openpyxl')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "chitrain['food'] = 'chicken'\n",
    "cotrain = pd.read_excel(\"Corn_oil_scoring.xlsx\", engine='openpyxl')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "cotrain['food'] = 'corn oil'\n",
    "gtrain = pd.read_excel(\"Ginger_scoring.xlsx\", engine='openpyxl')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "gtrain['food'] = 'ginger'\n",
    "mtrain = pd.read_excel(\"Mussel_scoring.xlsx\", engine='openpyxl')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "mtrain['food'] = 'mussel'\n",
    "petrain = pd.read_excel(\"Peanut_scoring.xlsx\", engine='openpyxl')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "petrain['food'] = 'peanut'\n",
    "potrain = pd.read_excel(\"Potato_scoring.xlsx\", engine='openpyxl')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "potrain['food'] = 'potato'\n",
    "strain = pd.read_excel(\"Soybean_scoring.xlsx\", engine='openpyxl')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "strain['food'] = 'soybean'\n",
    "ttrain = pd.read_excel(\"Tomato_scoring.xlsx\", engine='openpyxl')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "ttrain['food'] = 'tomato'\n",
    "wtrain = pd.read_excel(\"Wheat_scoring.xlsx\", engine='openpyxl')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms', 'is_useful']]\n",
    "wtrain['food'] = 'wheat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrain = atrain[atrain['abstract'].notnull()]\n",
    "chetrain = chetrain[chetrain['abstract'].notnull()]\n",
    "chitrain = chitrain[chitrain['abstract'].notnull()]\n",
    "cotrain = cotrain[cotrain['abstract'].notnull()]\n",
    "gtrain = gtrain[gtrain['abstract'].notnull()]\n",
    "mtrain = mtrain[mtrain['abstract'].notnull()]\n",
    "petrain = petrain[petrain['abstract'].notnull()]\n",
    "potrain = potrain[potrain['abstract'].notnull()]\n",
    "strain = strain[strain['abstract'].notnull()]\n",
    "ttrain = ttrain[ttrain['abstract'].notnull()]\n",
    "wtrain = wtrain[wtrain['abstract'].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amodel_data = Filter()\n",
    "chemodel_data = Filter()\n",
    "chimodel_data = Filter()\n",
    "comodel_data = Filter()\n",
    "gmodel_data = Filter()\n",
    "mmodel_data = Filter()\n",
    "pemodel_data = Filter()\n",
    "pomodel_data = Filter()\n",
    "smodel_data = Filter()\n",
    "tmodel_data = Filter()\n",
    "wmodel_data = Filter()\n",
    "\n",
    "\n",
    "\n",
    "amodel_data.build_features(input_data = atrain, is_traindata = True)\n",
    "chemodel_data.build_features(input_data = chetrain, is_traindata = True)\n",
    "chimodel_data.build_features(input_data = chitrain, is_traindata = True)\n",
    "comodel_data.build_features(input_data = cotrain, is_traindata = True)\n",
    "gmodel_data.build_features(input_data = gtrain, is_traindata = True)\n",
    "mmodel_data.build_features(input_data = mtrain, is_traindata = True)\n",
    "pemodel_data.build_features(input_data = petrain, is_traindata = True)\n",
    "pomodel_data.build_features(input_data = potrain, is_traindata = True)\n",
    "smodel_data.build_features(input_data = strain, is_traindata = True)\n",
    "tmodel_data.build_features(input_data = ttrain, is_traindata = True)\n",
    "wmodel_data.build_features(input_data = wtrain, is_traindata = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_sample(df, train_frac=.7, val_frac=.2):\n",
    "    val_s1 = df[df['class'] == 0].sample(frac=val_frac)\n",
    "    val_s2 = df[df['class'] == 1].sample(frac=val_frac)\n",
    "    \n",
    "    val= pd.concat([val_s1, val_s2], axis=0, ignore_index=True, sort=False)\n",
    "    \n",
    "    df = df.drop(val_s1.index.tolist() + val_s2.index.tolist(), axis = 0)\n",
    "    \n",
    "    y = df.copy()['class']\n",
    "    x = df.copy().drop('class', axis = 1)\n",
    "    \n",
    "    #smote_x, smote_y = SMOTE().fit_sample(x, y)\n",
    "    #sm = SMOTE(random_state=0)\n",
    "    smote_x, smote_y = SMOTE().fit_resample(x, y)\n",
    "\n",
    "    df = pd.DataFrame(smote_x, columns = x.columns)\n",
    "    df['class'] = pd.Series(smote_y)\n",
    "    \n",
    "    train_s1 = df[df['class'] == 0].sample(frac=train_frac)\n",
    "    train_s2 = df[df['class'] == 1].sample(frac=train_frac)\n",
    "    \n",
    "    test = df.drop(train_s1.index.tolist() + train_s2.index.tolist(), axis = 0)\n",
    "    \n",
    "    return pd.concat([train_s1, train_s2], axis=0, ignore_index=True, sort=False), test, val\n",
    "    \n",
    "adata = amodel_data.data.copy()\n",
    "chedata = chemodel_data.data.copy()\n",
    "chidata = chimodel_data.data.copy()\n",
    "codata = comodel_data.data.copy()\n",
    "gdata = gmodel_data.data.copy()\n",
    "mdata = mmodel_data.data.copy()\n",
    "pedata = pemodel_data.data.copy()\n",
    "podata = pomodel_data.data.copy()\n",
    "sdata = smodel_data.data.copy()\n",
    "tdata = tmodel_data.data.copy()\n",
    "wdata = wmodel_data.data.copy()\n",
    "\n",
    "print(sum(adata['class'].tolist() + chedata['class'].tolist() + chidata['class'].tolist() + codata['class'].tolist() + gdata['class'].tolist()+ mdata['class'].tolist() + pedata['class'].tolist() + podata['class'].tolist() + sdata['class'].tolist() + tdata['class'].tolist() + wdata['class'].tolist()) / \n",
    "      len(adata['class'].tolist() + chedata['class'].tolist() + chidata['class'].tolist() + codata['class'].tolist() + gdata['class'].tolist()+ mdata['class'].tolist() + pedata['class'].tolist() + podata['class'].tolist() + sdata['class'].tolist() + tdata['class'].tolist() + wdata['class'].tolist()))\n",
    "print(sum(adata['class'].tolist() + chedata['class'].tolist() + chidata['class'].tolist() + codata['class'].tolist() + gdata['class'].tolist()+ mdata['class'].tolist() + pedata['class'].tolist() + podata['class'].tolist() + sdata['class'].tolist() + tdata['class'].tolist() + wdata['class'].tolist())) \n",
    "print(len(adata['class'].tolist() + chedata['class'].tolist() + chidata['class'].tolist() + codata['class'].tolist() + gdata['class'].tolist()+ mdata['class'].tolist() + pedata['class'].tolist() + podata['class'].tolist() + sdata['class'].tolist() + tdata['class'].tolist() + wdata['class'].tolist()))\n",
    "\n",
    "\n",
    "atrain, atest, aval = balanced_sample(adata)\n",
    "chetrain, chetest, cheval = balanced_sample(chedata)\n",
    "chitrain, chitest, chival = balanced_sample(chidata)\n",
    "cotrain, cotest, coval = balanced_sample(codata)\n",
    "gtrain, gtest, gval = balanced_sample(gdata)\n",
    "mtrain, mtest, mval = balanced_sample(mdata)\n",
    "petrain, petest, peval = balanced_sample(pedata)\n",
    "potrain, potest, poval = balanced_sample(podata)\n",
    "strain, stest, sval = balanced_sample(sdata)\n",
    "ttrain, ttest, tval = balanced_sample(tdata)\n",
    "wtrain, wtest, wval = balanced_sample(wdata)\n",
    "\n",
    "\n",
    "train = pd.concat([atrain, chetrain, chitrain, cotrain, gtrain, mtrain, petrain, potrain, strain, ttrain, wtrain], axis=0, ignore_index=True, sort=False)\n",
    "test = pd.concat([atest, chetest, chitest, cotest, gtest, mtest, petest, potest, stest, ttest, wtest], axis=0, ignore_index=True, sort=False)\n",
    "val = pd.concat([aval, cheval, chival, coval, gval, mval, peval, poval, sval, tval, wval], axis=0, ignore_index=True, sort=False) # Does not incorporate SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "y = train.copy()['class']\n",
    "x = train.copy().drop('class', axis = 1)\n",
    "\n",
    "model = XGBClassifier(learning_rate =0.1,\n",
    " n_estimators=300,\n",
    " #max_depth=5,\n",
    " max_depth=2,\n",
    " #min_child_weight=1,\n",
    " min_child_weight=2,\n",
    " #gamma=0,\n",
    " gamma=0.2,\n",
    " #subsample=0.8,\n",
    " subsample=0.9,\n",
    " #colsample_bytree=0.8,\n",
    " colsample_bytree=0.95,\n",
    " reg_alpha=1e-05,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "model.fit(x, y)\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=10)\n",
    "print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
    " \n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "kf_cv_scores = cross_val_score(model, x, y, cv=kfold )\n",
    "print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean()) \n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# RMSE Computation\n",
    "rmse = np.sqrt(MSE(y_test, predictions))\n",
    "print(\"RMSE : % f\" %(rmse))\n",
    "\n",
    "# Adjusted R-squared\n",
    "adjsR = 1 - (1-model.score(x, y))*(len(y)-1)/(len(y)-x.shape[1]-1)\n",
    "print(\"adj-R2 : % f\" %(adjsR))\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm1 = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm1)\n",
    "total1=sum(sum(cm1))\n",
    "\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature' : x.columns, 'importance' : model.feature_importances_}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Feature Extraction from Papers - CHANGE FILES AFTER THIS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change according to file/food\n",
    "Xtrain = pd.read_csv('C:\\\\...Data\\\\.....csv', encoding='latin1')[['PMID', 'abstract', 'paper', 'mesh_terms', 'qual_terms']]\n",
    "Xtrain['food'] = 'pasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain['is_useful']=1\n",
    "Xtrain = Xtrain[Xtrain['is_useful'].notnull()]\n",
    "Xtrain = Xtrain[Xtrain['abstract'].notnull()]\n",
    "Xtrain['is_useful'] = Xtrain['is_useful'].replace(2, 1, regex=True)\n",
    "Xtrain['is_useful'] = Xtrain['is_useful'].replace(0, 1, regex=True)\n",
    "\n",
    "#training_data = pd.concat([gtrain, ctrain], axis=0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmodel_data = Filter()\n",
    "\n",
    "Xmodel_data.build_features(input_data = Xtrain, is_traindata = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Classifier application to Papers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_df = Xmodel_data.data\n",
    "\n",
    "X_df_class_dropped = X_df.drop(columns=['class'])\n",
    "#X_df_class_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_probs = model.predict(X_df_class_dropped)\n",
    "#print(list(predicted_probs))\n",
    "\n",
    "list(predicted_probs).count(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_class_dropped['Estimated class'] = pd.Series(predicted_probs, index=X_df_class_dropped.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change according to file/food\n",
    "final_pd = pd.read_csv(\"C:\\\\...\\\\Data\\\\....csv\", encoding='latin1')[['PMID', 'abstract', 'paper', 'journal', 'webpage','year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pd = final_pd[final_pd['abstract'].notnull()]\n",
    "\n",
    "final_pd['Estimated class'] = pd.Series(predicted_probs, index=final_pd.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "\n",
    "# Change according to file/food\n",
    "writer = ExcelWriter('C:\\\\...\\\\Ranking\\\\..._Papers_Estimated_Class.xlsx')#\n",
    "final_pd.to_excel(writer,'Pasta_Papers')#\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
